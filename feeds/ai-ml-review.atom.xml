<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Higher Bytes</title><link href="http://bt3gl.github.io/" rel="alternate"></link><link href="http://bt3gl.github.io/feeds/ai-ml-review.atom.xml" rel="self"></link><id>http://bt3gl.github.io/</id><updated>2016-07-30T00:00:00-04:00</updated><entry><title>ICYM AI &amp; ML - Week #30 of 2016</title><link href="http://bt3gl.github.io/icym-ai-ml-week-30-of-2016.html" rel="alternate"></link><updated>2016-07-30T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-07-30:icym-ai-ml-week-30-of-2016.html</id><summary type="html">&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;. This is a 2-years-old article, but a very well-written high-level explanation of the topology of low-dimensional NNs. "&lt;em&gt;The task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.&lt;/em&gt;"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-01-Visualizing-Representations/"&gt;Visualizing Representations: Deep Learning and Human Beings.&lt;/a&gt; Another Christopher Olah's great post, now on NN's different layers representations, tanging some philosophic aspects of it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/cnnembed/"&gt;Karpathy's t-SNE visualization of CNN codes.&lt;/a&gt; He takes the 50k ILSVRC 2012 validation images, extracts the 4096-dimensional fc7 CNN features using Caffe and then uses Barnes-Hut t-SNE to compute a 2-dimensional embedding that respects the high-dimensional (L2) distances. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground"&gt;Understanding neural networks with TensorFlow Playground&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html"&gt;Karpathy's convnetjs viz tool.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://download.tensorflow.org/paper/whitepaper2015.pdf"&gt;Tensor Flow Whitepaper, (Abadi, &lt;strong&gt;et al.&lt;/strong&gt; (2014)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44921.pdf"&gt;Large-Scale Deep Learning for Intelligent Computer Systems by Jeff Dean&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Yolo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Ics9CjRSMfc"&gt;Baidu AI Composer&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remember that the hidden layer learns a representation so that the data is linearly separable, so that's is how you do separate a spiral two-dimensional dataset using Tensorflow playground and Convnetjs:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With tanh:&lt;/p&gt;
&lt;p&gt;&lt;img alt="tahn2" height="300px" src="./tensor_flow_playground/tanh2.png" width="400px" /&gt;  &lt;img alt="tahn11" height="300px" src="./tensor_flow_playground/tan1.png" width="400px" /&gt;   &lt;img alt="tan2" height="300px" src="./tensor_flow_playground/tan2.png" width="400px" /&gt;   &lt;img alt="tan3" height="300px" src="./tensor_flow_playground/tan3.png" width="400px" /&gt; &lt;/p&gt;
&lt;p&gt;With ReLU:&lt;/p&gt;
&lt;p&gt;&lt;img alt="relu2" height="300px" src="./tensor_flow_playground/relu2.png" width="400px" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;That's is how you do not separate a spiral two-dimensional dataset:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="linear" height="300px" src="./tensor_flow_playground/linear.png" width="400px" /&gt; &lt;img alt="relu_no" height="300px" src="./tensor_flow_playground/relu_no.png" width="400px" /&gt; &lt;img alt="sigmoid" height="300px" src="./tensor_flow_playground/sigmoid.png" width="400px" /&gt;  &lt;img alt="relu_no2" height="300px" src="./tensor_flow_playground/relu_no2.png" width="400px" /&gt;  &lt;img alt="relu_no3" height="300px" src="./tensor_flow_playground/relu_no3.png" width="400px" /&gt;  &lt;img alt="relu_no4" height="300px" src="./tensor_flow_playground/relu_no4.png" width="400px" /&gt; &lt;/p&gt;</summary></entry><entry><title>ICYM AI &amp; ML - Week #29 of 2016</title><link href="http://bt3gl.github.io/icym-ai-ml-week-29-of-2016.html" rel="alternate"></link><updated>2016-07-23T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-07-23:icym-ai-ml-week-29-of-2016.html</id><summary type="html">&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1409.4842.pdf"&gt;Going deeper with Convolutions (Szegedy, &lt;strong&gt;et al.&lt;/strong&gt; (2014)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=yxxRAHVtafI"&gt;The Science of Talking with Computers&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=NK6O8CtI2D4"&gt;Megan Smith: Perspectives on artificial intelligence from the White House&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=6eBpjEdgSm0"&gt;NVIDIA Deep Learning Course: Class #1 – Introduction to Deep Learning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Yolo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=u2t77mQmJiY"&gt;A genetic algorithm learns how to fight!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>ICYM AI &amp; ML - Week #28 of 2016</title><link href="http://bt3gl.github.io/icym-ai-ml-week-28-of-2016.html" rel="alternate"></link><updated>2016-07-16T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-07-16:icym-ai-ml-week-28-of-2016.html</id><summary type="html">&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.benjamintd.com/blog/spynet/?utm_campaign=Artificial%2BIntelligence%2BWeekly&amp;amp;utm_medium=web&amp;amp;utm_source=Artificial_Intelligence_Weekly_42"&gt;Teaching an AI to write Python code with Python code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://efavdb.com/deep-learning-with-jupyter-on-aws/"&gt;Starting DL with Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.gc2fcdcce7_216_515"&gt;DIY Deep Learning for Vision:  a Hands-On Tutorial with Caffe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html"&gt;Wide &amp;amp; Deep Learning: Better Together with TensorFlow&lt;/a&gt; - &lt;em&gt;Can we teach computers to learn like humans do, by combining the power of memorization and generalization?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf"&gt;Mastering the Game of Go with Deep Neural Networks and Tree Search&lt;/a&gt;. Basically:
        * Values networks to evaluate board positions and policy networks to select moves.
        * Trained with supervised learning from human expert games and reinforcement learning from games of self-play.
        * NN playS Go at the level of state-of-art Monte-Carlo tree search that simulate thousands of random games of self-play.
        * New search algorithm that combines Monte-Carlo simulation with value and policy network&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1607.02533v1.pdf"&gt;Adversarial Examples in the Physical World&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf"&gt;Deep Residual Networks, Kaiming He, Facebook AI Research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Resources_files/AlphaGo_IJCAI.pdf"&gt;AlphaGo Preso&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XkltShNd6XE"&gt;Prof. Jürgen Schmidhuber - True Artificial Intelligence Will Change Everything&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Yolo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Remember: "All games of perfect information have an optimal value function which determines the outcome of the game".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://diogenes.greedbag.com/buy/ghost-lanes-0/"&gt;Post-Rock as it best: Ghost Lanes&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>